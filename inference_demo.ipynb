{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57ea5527-26fa-4733-a690-eb58dbd1d6d1",
   "metadata": {},
   "source": [
    "# Demo notebook for predictions with GenSIM\n",
    "\n",
    "This is a notebook showing how GenSIM and its pre-trained weights can be used for efficient Arctic-wide forecasting. In this notebook you will learn how the expected data looks like, how the model can be used for auto-regressive prediction and how to reproduce some of the results presented in the manuscript."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960212e4-3a8e-427c-a890-d0e6f72d3b45",
   "metadata": {},
   "source": [
    "## Download demo dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df6e4fa-ef0d-4fdf-8e1b-1c754b7315ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to download demo file from Zenodo\n",
    "# ! wget -O data/auxiliary/ds_demo.nc https://zenodo.org/records/17535317/files/ds_demo.nc?download=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34e4eca-a934-4c55-aa4e-aa8f1f0c577b",
   "metadata": {},
   "source": [
    "## Download model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddd7485-db44-41d7-bae7-15ae1aa1404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to download model weights from HuggingFace\n",
    "# When prompted for a password, use an access token with write permissions.\n",
    "# Generate one from your settings: https://huggingface.co/settings/tokens\n",
    "\n",
    "# ! git lfs install\n",
    "# ! git clone https://huggingface.co/tobifinn/GenSIM data/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfb9bfd-2c80-4964-8d5c-5584052c916b",
   "metadata": {},
   "source": [
    "# Load the needed libraries\n",
    "\n",
    "These are just the minimal libraries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8325967d-550c-48af-b719-ca2359f18e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For empty context manager\n",
    "import contextlib\n",
    "# To load the data\n",
    "import xarray as xr\n",
    "# To read in the config and initialize model\n",
    "from hydra import compose, initialize\n",
    "from hydra.utils import instantiate\n",
    "# To load the network weights\n",
    "from safetensors import safe_open\n",
    "# To run the prediction\n",
    "import torch\n",
    "# For general computation\n",
    "import numpy as np\n",
    "# For nice plotting with timeaxis\n",
    "import pandas as pd\n",
    "# For metric estimation\n",
    "from scipy import stats\n",
    "# For progress bar\n",
    "from tqdm.notebook import tqdm \n",
    "\n",
    "# To plot the predictions\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as mpl_gs\n",
    "import matplotlib.colors as mpl_c\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy\n",
    "import cmocean\n",
    "\n",
    "# To define the flow matching model\n",
    "from gensim.model import FlowMatchingModel\n",
    "import gensim.network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23292cb1-185c-4a68-9b5c-235347e1f458",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad00c10-47a2-4c99-8953-c6578e75358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the manual seed, used for the sampling in the prediction steps\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Number of ensemble members\n",
    "n_ens = 8\n",
    "\n",
    "# Device used for inference (use of single GPU only)\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# To activate mixed precision with which the model was (only useable for recent Nvidia GPUs)\n",
    "use_mixed = True\n",
    "\n",
    "# Path to the model checkpoints\n",
    "model_path = \"data/models/model_weights_ema.safetensors\"\n",
    "\n",
    "# To override the use of flash attention (only available for recent NVIDIA GPUs)\n",
    "gensim.network.USE_FLASH_ATTN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6287417f-05a9-44b1-beee-338283097701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Context manager used if mixed precision is activated\n",
    "prediction_context = torch.amp.autocast(\"cuda\", dtype=torch.bfloat16) if use_mixed else contextlib.suppress()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e64c36-d7fa-4c60-a427-6dc5ab8eff10",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04a50f9-677b-44d7-81ce-546fdd048308",
   "metadata": {},
   "source": [
    "## Auxiliary data\n",
    "\n",
    "The auxiliary dataset is already included in this repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89f8b93-979f-4b6d-9d07-b5d2d04c9ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_aux = xr.open_dataset(\"data/auxiliary/ds_auxiliary.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fecd4f-f5eb-40c2-82e4-06f2c54d6b46",
   "metadata": {},
   "source": [
    "### Create mesh\n",
    "\n",
    "The mesh coordinates are given as Cartesian coordinates in the cell centers in a North Polar Stereographic projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd3b924-28e6-431d-a109-139ab5a6d714",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = ds_aux[[\"x_coord\", \"y_coord\"]].to_dataarray(\"coord_names\").values\n",
    "\n",
    "# Convert from metres into kilometres\n",
    "mesh = mesh / 1000\n",
    "\n",
    "# Add ensemble dimension\n",
    "mesh = mesh[None].repeat(n_ens, axis=0)\n",
    "\n",
    "# Convert into torch tensor\n",
    "mesh = torch.as_tensor(mesh, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc33e9eb-2fde-466e-be48-5c1c35eb95bc",
   "metadata": {},
   "source": [
    "### Create mask\n",
    "\n",
    "The mask is set to False (0) for land and set to True (1) for open ocean. The mask will be used within the neural network for the predictions to represent interactions with land and to mask the prediction over land."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80425185-6384-46d6-af0c-633d85e47519",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ds_aux[\"mask\"].values\n",
    "\n",
    "# Add ensemble dimension\n",
    "mask = mask[None, None].repeat(n_ens, axis=0)\n",
    "\n",
    "# Convert into torch tensor\n",
    "mask = torch.as_tensor(mask, device=device)\n",
    "\n",
    "# Number of valid grid points needed for metric estimation\n",
    "n_grid = ds_aux[\"mask\"].values.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d29b605-91d8-4206-8a55-b58568b0f922",
   "metadata": {},
   "source": [
    "## Load the dataset\n",
    "\n",
    "The here-used demo dataset contains all sea-ice states and forcings for four days between 2018-01-01 03:00 and 2018-01-04 15:00 in 12-hour steps as extracted from the original testing dataset.\n",
    "\n",
    "We will split the data into initial conditions, forcings, and the truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3246615-b329-41ee-b599-b03e1e3a7e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the netCDF dataset\n",
    "ds_demo = xr.open_dataset(\"data/auxiliary/ds_demo.nc\")[\"datacube\"]\n",
    "\n",
    "# Fill cell with land (stored as NaN) with zeros\n",
    "ds_demo = ds_demo.fillna(0)\n",
    "\n",
    "# Get how many prediction steps we should do\n",
    "n_steps = len(ds_demo[\"time\"]) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850894f9-5538-4144-9ed2-67436f8c3c7d",
   "metadata": {},
   "source": [
    "### Initial conditions\n",
    "\n",
    "The initial conditions are given by the six sea-ice states (thickness, concentration, damage, x-drift, y-drift, snow-on-ice thickness) at the first time step.\n",
    "\n",
    "The shape of the initial conditions will be (n_ens, 6, 512, 512) with dimensions (ensemble members, ariables, y, x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c89621d-fe24-4e7b-92e4-6c1d60357150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice first time step\n",
    "ds_initial = ds_demo.isel(time=0)\n",
    "\n",
    "# Get only state variables\n",
    "ds_initial = ds_initial.sel(var_names=[\"sit\", \"sic\", \"sid\", \"siu\", \"siv\", \"snt\"])\n",
    "\n",
    "# Create an ensemble of initial conditions\n",
    "initial_conditions = ds_initial.values[None].repeat(n_ens, axis=0)\n",
    "\n",
    "# Convert the initial conditions into a torch tensor\n",
    "initial_conditions = torch.as_tensor(initial_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b98213-4fcd-4ecb-95f9-55693d4cbf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show how the initial conditions look like\n",
    "print(ds_initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984551d9-b269-477e-9520-759c92c6513c",
   "metadata": {},
   "source": [
    "### Forcings\n",
    "\n",
    "The forcings are extracted from the ERA5 reanalysis and given by the eight variables (2-metre temperature, 2-metre specific humidity, wind rotated in x-direction, wind rotated in y-direction).\n",
    "\n",
    "For remaining more efficient, we will leave the forcings on the CPU as numpy array and convert them into the torch tensor on the GPU during inference time.\n",
    "\n",
    "The shape of the forcings will be (n_ens, 2, 4, 512, 512) with dimensions (ensemble members, timesteps t and t+12 h, variables, y, x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1ad45d-f236-4124-9774-4c852375bb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select forcings variables\n",
    "ds_forcings = ds_demo.sel(var_names=['tus', 'huss', 'uas', 'vas'])\n",
    "\n",
    "# Create ensemble dimension\n",
    "forcings = ds_forcings.values[None].repeat(n_ens, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5fb3db-c686-448b-af93-7b65da0648a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show how the forcings look like\n",
    "print(ds_forcings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02ea3d1-1c6b-4bb3-ba4b-6f4e2d319189",
   "metadata": {},
   "source": [
    "The degree day features will be only used for the current timestep, positive degree days over 30 days, freezing degree days over 30 days, positive degree days over 366 days, freezing degree days over 366 days). The degree day features are used as proxies for a longer thermodynamical development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fecf04-e037-4872-8ab0-e4125d0f150d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select degree day variables\n",
    "ds_degree_days = ds_demo.sel(var_names=['pdd_month', 'fdd_month', 'pdd_year', 'fdd_year'])\n",
    "\n",
    "# Create ensemble dimension\n",
    "degree_days = ds_degree_days.values[None].repeat(n_ens, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87120baf-8e05-42c5-9908-39bed9354016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To show how the degree days look like\n",
    "print(ds_degree_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbfaaec-e0af-40b8-9426-850ff8b0d1d5",
   "metadata": {},
   "source": [
    "## Truth\n",
    "\n",
    "Our truth is given as trajectory of sea-ice states over all timesteps.\n",
    "\n",
    "The truth will stay as xarray array on the CPU.\n",
    "\n",
    "The shape of the truth will be (8, 6, 512, 512) with dimensions (all time steps, variables, y, x)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25e974b-c82b-4e87-8805-db93545d7709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only state variables\n",
    "ds_truth = ds_demo.sel(var_names=[\"sit\", \"sic\", \"sid\", \"siu\", \"siv\", \"snt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c601d13d-655e-4e28-9c64-9745e7dbebc5",
   "metadata": {},
   "source": [
    "# Load the model\n",
    "\n",
    "The model is defined as all-inclusive wrapping: it includes the neural network, the encoder/decoder (scaling) from/to physical space, the second-order flow matching sampler, the domain decomposition for inference.\n",
    "\n",
    "The configuration is performed with hydra. Based on this configuration the model will be built. After building the model, the network weights will be loaded, and the model will be potentially compiled with a just-in-time compiler for faster inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaae609-0a85-4ca1-bcd4-a972fbca72fc",
   "metadata": {},
   "source": [
    "## Load the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3198cc-b48c-4478-9aaa-653532624719",
   "metadata": {},
   "outputs": [],
   "source": [
    "with initialize(version_base=None, config_path=\".\", job_name=\"prediction\"):\n",
    "    cfg = compose(\n",
    "        config_name=\"config.yaml\",\n",
    "        overrides=[]                          # If you want to change config options on the fly\n",
    "    )\n",
    "\n",
    "# We are only interested in the surrogate model part ofthe config\n",
    "cfg = cfg[\"surrogate\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a620918-1167-459d-9169-171849e2dc65",
   "metadata": {},
   "source": [
    "## Instantiate the model\n",
    "\n",
    "The model will be instantiated from the loaded config file. The instantiation will create all needed elements for the model. The model is then copied to the selected device (likely GPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0dadf5-bca5-4139-a892-cf678d691b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = instantiate(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f88fdc-817c-481d-b2fa-4e0876f4caed",
   "metadata": {},
   "source": [
    "## Load the neural network weights\n",
    "\n",
    "The neural network weights are stored as safetensor to avoid contaminated files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf7f086-1919-4b2d-8f03-0f068f425982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the safetensor\n",
    "with safe_open(model_path, framework=\"pt\", device=\"cuda\") as f:\n",
    "    saved_keys = list(f.keys())\n",
    "    \n",
    "    # Get the network state dict\n",
    "    network_state_dict = model.network.state_dict()\n",
    "\n",
    "    # Update the network state dict with the weights from the tensor\n",
    "    network_state_dict.update({key: f.get_tensor(key) for key in saved_keys})\n",
    "\n",
    "    # Load the updated state dict into the network\n",
    "    model.network.load_state_dict(network_state_dict)\n",
    "\n",
    "    # Helpful message if keys are missing\n",
    "    missing_keys = [k for key in network_state_dict.keys() if key not in saved_keys]\n",
    "    if missing_keys:\n",
    "        print(\"Missing keys in loaded weights:\", missing_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c7ebdd-a91b-4d39-87f4-c535b426f286",
   "metadata": {},
   "source": [
    "## Compile model\n",
    "\n",
    "The model will be moved to the right device and potentially compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a2cd47-ee4a-4b06-a4c5-d377cb9f515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model components to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Set the correct inference model (set compile to False to deactivate compilation of model)\n",
    "model.set_inference_model(compile=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5699840-a579-4b9b-a388-5a4bacf8546b",
   "metadata": {},
   "source": [
    "# Prediction\n",
    "\n",
    "To produce the trajectory, we will loop through prediction steps. For each prediction step, the forcings will be load to GPU and the model will produce the prediction. This prediction is then stored in a trajectory list. This trajectory list will be concatenated later and converted into a xarray.DataArray like the truth.\n",
    "\n",
    "This explicit and readable implementation as shown here is not the most efficient, e.g., the fields could be pre-stored on GPU, reducing the need to copy tensors between CPU and GPU. Hence, the time needed here is not representative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774da8f9-11bf-4a12-9b65-bf6d6d4607c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resolution needed for prediction\n",
    "resolution = torch.full((n_ens, 1), 12.5, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9360d9e8-4792-47aa-accc-dc2a33931dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise the trajectory list\n",
    "trajectory = [initial_conditions]\n",
    "\n",
    "# Set the current conditions to the initial conditions\n",
    "curr_conditions = initial_conditions.to(device)\n",
    "\n",
    "# Loop through all forecasting steps\n",
    "for step in tqdm(range(n_steps)):\n",
    "    # Get current forcings as tensor\n",
    "    curr_forcings = forcings[:, step:step+2]\n",
    "    curr_forcings = torch.as_tensor(curr_forcings, device=device)\n",
    "\n",
    "    # Get current degree days as tensor\n",
    "    curr_degree_days = degree_days[:, step]\n",
    "    curr_degree_days = torch.as_tensor(curr_degree_days, device=device)\n",
    "    \n",
    "    with prediction_context:\n",
    "        # Make the prediction\n",
    "        curr_conditions = model(\n",
    "            curr_conditions[:, None],  # Add timeaxis (only current timestep)\n",
    "            curr_forcings,\n",
    "            resolution=resolution,\n",
    "            mesh=mesh,\n",
    "            mask=mask,\n",
    "            degree_days=curr_degree_days\n",
    "        )\n",
    "\n",
    "    # Add the current prediction to the trajectory list\n",
    "    trajectory.append(curr_conditions.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d568ab-3cd6-4162-9e5f-ec1df6848957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack the trajectory into a time axis\n",
    "predictions = torch.stack(trajectory, axis=0)\n",
    "\n",
    "# Convert predictions from torch to numpy\n",
    "predictions = predictions.numpy()\n",
    "\n",
    "# Copy predictions into xarray\n",
    "predictions = ds_truth.expand_dims(ensemble=np.arange(n_ens), axis=1).copy(data=predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88644daa-9b21-45fb-9409-6394219d46de",
   "metadata": {},
   "source": [
    "# Plotting\n",
    "\n",
    "We will plot metrics for the quality of the predictions as well as individual predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9c7992-c013-4905-b847-6da534e3526b",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "As simple yet hard to beat reference in sea-ice modelling, we will use a persistence forecast where the initial conditions are predicted through the whole time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225031bd-0ea7-44b8-8dce-70df623ddde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the initial conditions for all time steps\n",
    "persistence = ds_initial.expand_dims(time=ds_truth[\"time\"], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9059dc8-ac16-4d7d-9369-1d26dd0f9ace",
   "metadata": {},
   "source": [
    "## Prediction error\n",
    "\n",
    "We will estimate the prediction error for the ensemble members and the ensemble member independently. We will additionally estimate the error only over cells with ocean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f9635d-93e6-410d-b864-baa550a6d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error of persistence\n",
    "error_persist = persistence-ds_truth\n",
    "rmse_persist = np.sqrt((error_persist**2).sum([\"y\", \"x\"])/n_grid)\n",
    "\n",
    "# Error of ensemble members\n",
    "error_members = predictions-ds_truth\n",
    "rmse_members = np.sqrt((error_members**2).sum([\"ensemble\", \"y\", \"x\"])/n_ens/n_grid)\n",
    "\n",
    "# Error of ensemble mean\n",
    "error_mean = predictions.mean(\"ensemble\")-ds_truth\n",
    "rmse_mean = np.sqrt((error_mean**2).sum([\"y\", \"x\"])/n_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1381e05d-1a5b-4b48-ad92-de92a5f1b439",
   "metadata": {},
   "outputs": [],
   "source": [
    "timedelta_axis = pd.timedelta_range(\"0h\", periods=n_steps+1, freq=\"12h\") / pd.Timedelta(\"1d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710ad772-4626-4a25-85e4-faad216c1d16",
   "metadata": {},
   "source": [
    "### Plot the error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2776c82-896d-4b3f-ada8-ecf6e509a38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, gridspec_kw={\"hspace\": 0.10})\n",
    "ax[0].plot(\n",
    "    timedelta_axis, rmse_persist.sel(var_names=\"sit\"),\n",
    "    c=\"0.5\", ls=\":\", label=\"Persistence\", lw=1\n",
    ")\n",
    "ax[0].plot(\n",
    "    timedelta_axis, rmse_members.sel(var_names=\"sit\"),\n",
    "    c=\"#E62A07\", ls=\"--\", label=\"GenSIM member\", lw=1\n",
    ")\n",
    "ax[0].plot(\n",
    "    timedelta_axis, rmse_mean.sel(var_names=\"sit\"),\n",
    "    c=\"#E65007\", ls=\"-\", label=\"GenSIM mean\", lw=1.5\n",
    ")\n",
    "ax[0].set_xlim(0, 3.6)\n",
    "ax[0].set_xticks([0, 1, 2, 3], [])\n",
    "ax[0].set_ylim(0, 0.17)\n",
    "ax[0].set_ylabel(\"RMSE Thickness (m)\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(\n",
    "    timedelta_axis, rmse_persist.sel(var_names=\"siu\"),\n",
    "    c=\"0.5\", ls=\":\", label=\"Persistence\", lw=1\n",
    ")\n",
    "ax[1].plot(\n",
    "    timedelta_axis, rmse_members.sel(var_names=\"siu\"),\n",
    "    c=\"#E62A07\", ls=\"--\", label=\"GenSIM member\", lw=1\n",
    ")\n",
    "ax[1].plot(\n",
    "    timedelta_axis, rmse_mean.sel(var_names=\"siu\"),\n",
    "    c=\"#E65007\", ls=\"-\", label=\"GenSIM mean\", lw=1.5\n",
    ")\n",
    "ax[1].set_xlim(0, 3.6)\n",
    "ax[1].set_xticks([0, 1, 2, 3], [0, 1, 2, 3])\n",
    "ax[1].set_xlabel(\"Lead time (days)\")\n",
    "ax[1].set_ylim(0, 0.08)\n",
    "ax[1].set_ylabel(\"RMSE x-drift (m/s)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4965ffe-5805-4154-b7fe-a28efa59bd69",
   "metadata": {},
   "source": [
    "GenSIM improves upon the persistence forecasts for all variables and all lead times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743f3853-6612-4190-8117-f342119e42e0",
   "metadata": {},
   "source": [
    "## Power spectrum\n",
    "\n",
    "We will estimate the power spectrum to analyse the behavior of the forecasts with respect to smoothing. We will only analyse the predictions after 3.5 days of forecasting lead time as we expect the strongest smoothing there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756f0ecb-e22f-4687-a7b0-e7e657e2cb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slice specifying central Arctic (128x128 grid points)\n",
    "SPECTRUM_SLICES = (\n",
    "    slice(315, 443),\n",
    "    slice(180, 308)\n",
    ")\n",
    "\n",
    "# Settings needed to estimate spectrum\n",
    "norm = 1 / 128 / 128\n",
    "yc, xc = np.ogrid[np.s_[-64:64],np.s_[-64:64]]\n",
    "radius = np.sqrt(yc**2 + xc**2).round()\n",
    "r_range = np.arange(65)\n",
    "freqs = np.fft.fftfreq(128, 1)[:64]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c603dd06-7aa9-44a6-bc41-e42134f042e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to estimate the spectrum\n",
    "def estimate_spectrum(field):\n",
    "    psd = np.fft.fftshift(np.fft.fft2(field))\n",
    "    psd = np.abs(psd)**2 * norm\n",
    "    psd = stats.binned_statistic(\n",
    "        radius.flatten(), psd.flatten(), bins=r_range-0.5\n",
    "    ).statistic\n",
    "    return psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57bc5be-4e13-4ff9-9cb7-a615ca666da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum_truth = xr.apply_ufunc(\n",
    "    estimate_spectrum,\n",
    "    ds_truth.isel(time=-1, y=SPECTRUM_SLICES[0], x=SPECTRUM_SLICES[1]),   # Slice last step and central Arctic\n",
    "    input_core_dims=[[\"y\", \"x\"]],\n",
    "    output_core_dims=[[\"freqs\"]],\n",
    "    vectorize=True,\n",
    "    dask='parallelized',\n",
    "    output_dtypes=[np.float32],\n",
    "    dask_gufunc_kwargs=dict(\n",
    "        output_sizes={\"freqs\": 64}\n",
    "    )\n",
    ").compute()\n",
    "\n",
    "spectrum_members = xr.apply_ufunc(\n",
    "    estimate_spectrum,\n",
    "    predictions.isel(time=-1, y=SPECTRUM_SLICES[0], x=SPECTRUM_SLICES[1]),   # Slice last step and central Arctic\n",
    "    input_core_dims=[[\"y\", \"x\"]],\n",
    "    output_core_dims=[[\"freqs\"]],\n",
    "    vectorize=True,\n",
    "    dask='parallelized',\n",
    "    output_dtypes=[np.float32],\n",
    "    dask_gufunc_kwargs=dict(\n",
    "        output_sizes={\"freqs\": 64}\n",
    "    )\n",
    ").compute()\n",
    "# Average the spectrum across the ensemble dimension in log space\n",
    "spectrum_members = np.exp(np.log(spectrum_members).mean([\"ensemble\"]))\n",
    "\n",
    "spectrum_mean = xr.apply_ufunc(\n",
    "    estimate_spectrum,\n",
    "    predictions.mean(\"ensemble\").isel(time=-1, y=SPECTRUM_SLICES[0], x=SPECTRUM_SLICES[1]),   # Take ensemble mean and slice last step and central Arctic\n",
    "    input_core_dims=[[\"y\", \"x\"]],\n",
    "    output_core_dims=[[\"freqs\"]],\n",
    "    vectorize=True,\n",
    "    dask='parallelized',\n",
    "    output_dtypes=[np.float32],\n",
    "    dask_gufunc_kwargs=dict(\n",
    "        output_sizes={\"freqs\": 64}\n",
    "    )\n",
    ").compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3213539-e10c-4b6e-9c32-432a2e55c728",
   "metadata": {},
   "source": [
    "### Plot the spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d21d059-da29-4330-90b8-5e63d13e369e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, gridspec_kw={\"hspace\": 0.10})\n",
    "ax[0].loglog(\n",
    "    64*24/np.arange(1, 65),\n",
    "    spectrum_truth.sel(var_names=\"sit\"),\n",
    "    c=\"black\", label=\"Truth\", lw=1.,\n",
    ")\n",
    "ax[0].plot(\n",
    "    64*24/np.arange(1, 65),\n",
    "    spectrum_mean.sel(var_names=\"sit\"),\n",
    "    c=\"#E65007\", label=\"GenSIM\", lw=1.5\n",
    ")\n",
    "ax[0].plot(\n",
    "    64*24/np.arange(1, 65),\n",
    "    spectrum_members.sel(var_names=\"sit\"),\n",
    "    c=\"#E62A07\", ls=\"--\", label=\"GenSIM member\", lw=1\n",
    ")\n",
    "ax[0].set_xscale(\"log\")\n",
    "ax[0].set_yscale(\"log\")\n",
    "ax[0].set_xticks([400, 200, 100, 50, 25])\n",
    "ax[0].set_xticklabels([])\n",
    "ax[0].set_xticks([], minor=True)\n",
    "ax[0].set_xlim(500, 23)\n",
    "ax[0].set_ylim(3E-3, 1E2)\n",
    "ax[0].set_ylabel(\"Energy (m$^{2}$)\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].loglog(\n",
    "    64*24/np.arange(1, 65),\n",
    "    spectrum_truth.sel(var_names=\"siu\"),\n",
    "    c=\"black\", label=\"Truth\", lw=1.,\n",
    ")\n",
    "ax[1].plot(\n",
    "    64*24/np.arange(1, 65),\n",
    "    spectrum_mean.sel(var_names=\"siu\"),\n",
    "    c=\"#E65007\", label=\"GenSIM\", lw=1.5\n",
    ")\n",
    "ax[1].plot(\n",
    "    64*24/np.arange(1, 65),\n",
    "    spectrum_members.sel(var_names=\"siu\"),\n",
    "    c=\"#E62A07\", ls=\"--\", label=\"GenSIM member\", lw=1\n",
    ")\n",
    "ax[1].set_xscale(\"log\")\n",
    "ax[1].set_yscale(\"log\")\n",
    "ax[1].set_xticks([400, 200, 100, 50, 25])\n",
    "ax[1].set_xticklabels([400, 200, 100, 50, 25])\n",
    "ax[1].set_xticks([], minor=True)\n",
    "ax[1].set_xlabel(\"Resolution (km)\")\n",
    "ax[1].set_xlim(500, 23)\n",
    "ax[1].set_ylim(3E-6, 2E-1)\n",
    "ax[1].set_ylabel(\"Energy (m$^{2}$ s$^{-2}$)\")\n",
    "\n",
    "fig.align_ylabels(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f647f4-5ce5-48f0-875b-ed610a88c28a",
   "metadata": {},
   "source": [
    "## Extent accuracy\n",
    "\n",
    "Estimate the accuracy with which the sea-ice edge is predicted. The threshold is set to 0.15. The accuracy is given as matching extent between truth and forecast weighted by the area of a cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e333c2-6007-44c0-8004-9d5eab1d97b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a80d1c9-54c1-4caa-bdb6-1456bf4424a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "extent_truth = ds_truth.sel(var_names=\"sic\") > threshold\n",
    "extent_persistence = persistence.sel(var_names=\"sic\") > threshold\n",
    "extent_members = predictions.sel(var_names=\"sic\") > threshold\n",
    "extent_mean = predictions.mean(\"ensemble\").sel(var_names=\"sic\") > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ee2093-9871-40f6-bdf1-21936b54c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To estimate an area weighted accuracy\n",
    "# The weights is the cell area divided by the total area\n",
    "weights = ds_aux[\"cell_area\"].where(ds_aux[\"mask\"].astype(bool))\n",
    "weights /= weights.sum([\"x\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41df3023-425c-478f-8e6a-c983548c79b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_persist = ((extent_persistence == extent_truth)*weights).sum([\"x\", \"y\"])\n",
    "acc_members = ((extent_members == extent_truth)*weights).sum([\"x\", \"y\"]).mean(\"ensemble\")\n",
    "acc_mean = ((extent_mean == extent_truth)*weights).sum([\"x\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144762d7-257a-410d-84f3-7d98dc533f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(\n",
    "    timedelta_axis, acc_persist,\n",
    "    c=\"0.5\", ls=\":\", label=\"Persistence\", lw=1\n",
    ")\n",
    "ax.plot(\n",
    "    timedelta_axis, acc_members,\n",
    "    c=\"#E62A07\", ls=\"--\", label=\"GenSIM member\", lw=1\n",
    ")\n",
    "ax.plot(\n",
    "    timedelta_axis, acc_mean,\n",
    "    c=\"#E65007\", ls=\"-\", label=\"GenSIM mean\", lw=1.5\n",
    ")\n",
    "ax.set_xlim(0, 3.6)\n",
    "ax.set_xticks([0, 1, 2, 3], [0, 1, 2, 3])\n",
    "ax.set_xlabel(\"Lead time (days)\")\n",
    "ax.set_ylim(0.99, 1)\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f7c7ca-5134-45e7-a342-e18575a5460b",
   "metadata": {},
   "source": [
    "# Plot single forecasts\n",
    "\n",
    "For the single forecasts, we will imitate what was shown in Figure 2 of the paper after 2.5 and 3 days of forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79de01ab-6fcf-44e4-8aa7-29953e90883e",
   "metadata": {},
   "source": [
    "## Estimate deformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf547d6e-d6f6-4a27-9de4-81ad3e44c0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_deform(siu, siv, x_coord, y_coord):\n",
    "    area = 0.5 * (x_coord * y_coord.roll(abcd=-1) - x_coord.roll(abcd=-1) * y_coord).sum(\"abcd\", skipna=False)\n",
    "    du_x = (0.5 * (siu.roll(abcd=-1) + siu) * (y_coord.roll(abcd=-1) - y_coord)).sum(\"abcd\", skipna=False) / area\n",
    "    du_y = -(0.5 * (siu.roll(abcd=-1) + siu) * (x_coord.roll(abcd=-1) - x_coord)).sum(\"abcd\", skipna=False) / area\n",
    "    dv_x = (0.5 * (siv.roll(abcd=-1) + siv) * (y_coord.roll(abcd=-1) - y_coord)).sum(\"abcd\", skipna=False) / area\n",
    "    dv_y = -(0.5 * (siv.roll(abcd=-1) + siv) * (x_coord.roll(abcd=-1) - x_coord)).sum(\"abcd\", skipna=False) / area\n",
    "\n",
    "    div = du_x + dv_y\n",
    "    shear = ((du_x - dv_y)**2 + (du_y + dv_x)**2)**0.5\n",
    "    total = (div**2 + shear**2)**0.5\n",
    "    return xr.Dataset({\n",
    "        \"area\": area,\n",
    "        \"divergence\": div,\n",
    "        \"shear\": shear,\n",
    "        \"total\": total\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab35f659-86a3-45c0-998c-2c59f0faf654",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_mesh = np.stack(np.meshgrid(np.arange(512), np.arange(512), indexing=\"xy\"), axis=0)\n",
    "idx_rect = np.stack((\n",
    "    idx_mesh[:, :-1, :-1],\n",
    "    idx_mesh[:, :-1, 1:],\n",
    "    idx_mesh[:, 1:, 1:],\n",
    "    idx_mesh[:, 1:, :-1],\n",
    "), axis=-1).reshape(2, 511, 511, 4)\n",
    "idx_rect = xr.Dataset({\n",
    "    \"x\": ((\"yc\", \"xc\", \"abcd\"), idx_rect[0]),\n",
    "    \"y\": ((\"yc\", \"xc\", \"abcd\"), idx_rect[1]),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f58c2e-935a-4fa3-bfce-e302a1eee9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "deformation_truth = estimate_deform(\n",
    "    ds_truth.sel(var_names=\"siu\").isel(y=idx_rect[\"y\"], x=idx_rect[\"x\"]),\n",
    "    ds_truth.sel(var_names=\"siv\").isel(y=idx_rect[\"y\"], x=idx_rect[\"x\"]),\n",
    "    ds_aux[\"x_coord\"].isel(y=idx_rect[\"y\"], x=idx_rect[\"x\"]),\n",
    "    ds_aux[\"y_coord\"].isel(y=idx_rect[\"y\"], x=idx_rect[\"x\"]),\n",
    ")\n",
    "\n",
    "thickness_change_truth = ds_truth.sel(var_names=\"sit\").diff(\"time\", 1, label=\"lower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c80880b-1c72-4987-a104-cd66cbde7599",
   "metadata": {},
   "outputs": [],
   "source": [
    "deformation_prediction = estimate_deform(\n",
    "    predictions.sel(var_names=\"siu\").isel(y=idx_rect[\"y\"], x=idx_rect[\"x\"]),\n",
    "    predictions.sel(var_names=\"siv\").isel(y=idx_rect[\"y\"], x=idx_rect[\"x\"]),\n",
    "    ds_aux[\"x_coord\"].isel(y=idx_rect[\"y\"], x=idx_rect[\"x\"]),\n",
    "    ds_aux[\"y_coord\"].isel(y=idx_rect[\"y\"], x=idx_rect[\"x\"]),\n",
    ")\n",
    "\n",
    "thickness_change_prediction = predictions.sel(var_names=\"sit\").diff(\"time\", 1, label=\"lower\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee5f513-f4d1-48c8-beae-ee27d498788e",
   "metadata": {},
   "source": [
    "## Plot comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e3c275-96d9-4882-ae57-303af24fe3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default projection\n",
    "projection = ccrs.NorthPolarStereo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc1167a-6335-4756-bc75-905de986d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings with ensemble member and time steps should be used\n",
    "idx_mem = 0\n",
    "step_1 = -3\n",
    "step_2 = -2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb1eb8e-dd72-40c2-922c-a41509fd810e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 4), dpi=150)\n",
    "\n",
    "# Add subplots\n",
    "gs_truth = mpl_gs.GridSpec(nrows=2, ncols=3, left=0.04, right=0.48, wspace=0.05, hspace=0.1)\n",
    "ax_truth = [fig.add_subplot(subgs, projection=projection) for subgs in gs_truth]\n",
    "gs_prediction = mpl_gs.GridSpec(nrows=2, ncols=3, left=0.52, right=0.96, wspace=0.05, hspace=0.1)\n",
    "ax_prediction = [fig.add_subplot(subgs, projection=projection) for subgs in gs_prediction]\n",
    "\n",
    "for axi in ax_truth + ax_prediction:\n",
    "    axi.xaxis.set_visible(False)\n",
    "    axi.yaxis.set_visible(False)\n",
    "    axi.set_yticks([])\n",
    "    axi.spines.left.set_visible(False)\n",
    "    axi.spines.right.set_visible(False)\n",
    "    axi.spines.bottom.set_visible(False)\n",
    "    axi.set_extent([-1_500_000, 1_500_000, -800_000, 2_200_000], ccrs.NorthPolarStereo())\n",
    "    axi.add_feature(cartopy.feature.LAND, fc=\"xkcd:putty\", zorder=99, rasterized=True)\n",
    "\n",
    "# Sea-ice concentration\n",
    "sic_transform = lambda x: np.power(10_000, x)\n",
    "cf_sic = ax_truth[0].pcolormesh(\n",
    "    ds_aux[\"x_coord\"], ds_aux[\"y_coord\"],\n",
    "    sic_transform(ds_truth.sel(var_names=\"sic\")[step_1].values),\n",
    "    cmap=\"cmo.dense_r\", vmin=sic_transform(0.9), vmax=sic_transform(1.),\n",
    "    rasterized=True\n",
    ")\n",
    "cf_sic = ax_truth[3].pcolormesh(\n",
    "    ds_aux[\"x_coord\"], ds_aux[\"y_coord\"],\n",
    "    sic_transform(ds_truth.sel(var_names=\"sic\")[step_2].values),\n",
    "    cmap=\"cmo.dense_r\", vmin=sic_transform(0.9), vmax=sic_transform(1.),\n",
    "    rasterized=True\n",
    ")\n",
    "\n",
    "bbox = ax_truth[3].get_position()\n",
    "cax = fig.add_axes([bbox.x0+0.02, bbox.y0-0.02, bbox.x1-bbox.x0-0.04, 0.01])\n",
    "cbar = fig.colorbar(cf_sic, cax, orientation=\"horizontal\", extend=\"min\")\n",
    "cbar.set_label(r\"Concentration (1)\", labelpad=8)\n",
    "cbar.set_ticks(sic_transform([0.9, 0.95, 1]), labels=[\"0.9\", \"0.95\", \"1\"])\n",
    "for t in cbar.ax.get_yticklabels():\n",
    "    t.set_horizontalalignment('center')\n",
    "cax.xaxis.get_label().set_verticalalignment(\"baseline\")\n",
    "\n",
    "cf_sic = ax_prediction[0].pcolormesh(\n",
    "    ds_aux[\"x_coord\"], ds_aux[\"y_coord\"],\n",
    "    sic_transform(predictions.sel(var_names=\"sic\")[step_1, idx_mem].values),\n",
    "    cmap=\"cmo.dense_r\", vmin=sic_transform(0.9), vmax=sic_transform(1.),\n",
    "    rasterized=True\n",
    ")\n",
    "cf_sic = ax_prediction[3].pcolormesh(\n",
    "    ds_aux[\"x_coord\"], ds_aux[\"y_coord\"],\n",
    "    sic_transform(predictions.sel(var_names=\"sic\")[step_2, idx_mem].values),\n",
    "    cmap=\"cmo.dense_r\", vmin=sic_transform(0.9), vmax=sic_transform(1.),\n",
    "    rasterized=True\n",
    ")\n",
    "\n",
    "bbox = ax_prediction[3].get_position()\n",
    "cax = fig.add_axes([bbox.x0+0.02, bbox.y0-0.02, bbox.x1-bbox.x0-0.04, 0.01])\n",
    "cbar = fig.colorbar(cf_sic, cax, orientation=\"horizontal\", extend=\"min\")\n",
    "cbar.set_label(r\"Concentration (1)\", labelpad=8)\n",
    "cbar.set_ticks(sic_transform([0.9, 0.95, 1]), labels=[\"0.9\", \"0.95\", \"1\"])\n",
    "for t in cbar.ax.get_yticklabels():\n",
    "    t.set_horizontalalignment('center')\n",
    "cax.xaxis.get_label().set_verticalalignment(\"baseline\")\n",
    "\n",
    "# Divergence rate\n",
    "cf_div = ax_truth[1].pcolormesh(\n",
    "    ds_aux[\"x_coord\"], ds_aux[\"y_coord\"],\n",
    "    deformation_truth[\"divergence\"][step_1].values * 86400,\n",
    "    cmap=\"RdBu\",\n",
    "    norm=mpl_c.SymLogNorm(0.05, 1., vmin=-3, vmax=3),\n",
    "    rasterized=True\n",
    ")\n",
    "cf_div = ax_truth[4].pcolormesh(\n",
    "    ds_aux[\"x_coord\"], ds_aux[\"y_coord\"],\n",
    "    deformation_truth[\"divergence\"][step_2].values * 86400,\n",
    "    cmap=\"RdBu\",\n",
    "    norm=mpl_c.SymLogNorm(0.05, 1., vmin=-3, vmax=3),\n",
    "    rasterized=True\n",
    ")\n",
    "\n",
    "bbox = ax_truth[4].get_position()\n",
    "cax = fig.add_axes([bbox.x0+0.02, bbox.y0-0.02, bbox.x1-bbox.x0-0.04, 0.01])\n",
    "cbar = fig.colorbar(cf_div, cax, orientation=\"horizontal\", extend=\"both\")\n",
    "cbar.set_label(r\"Rate (day$^{-1}$)\", labelpad=8)\n",
    "cbar.set_ticks([-1, 0, 1], labels=[\"-1\", \"0\", \"1\"])\n",
    "cbar.set_ticks([], minor=True)\n",
    "for t in cbar.ax.get_yticklabels():\n",
    "    t.set_horizontalalignment('center')\n",
    "cax.xaxis.get_label().set_verticalalignment(\"baseline\")\n",
    "\n",
    "cf_div = ax_prediction[1].pcolormesh(\n",
    "    ds_aux[\"x_coord\"], ds_aux[\"y_coord\"],\n",
    "    deformation_prediction[\"divergence\"][step_1, idx_mem].values * 86400,\n",
    "    cmap=\"RdBu\",\n",
    "    norm=mpl_c.SymLogNorm(0.05, 1., vmin=-3, vmax=3),\n",
    "    rasterized=True\n",
    ")\n",
    "cf_div = ax_prediction[4].pcolormesh(\n",
    "    ds_aux[\"x_coord\"], ds_aux[\"y_coord\"],\n",
    "    deformation_prediction[\"divergence\"][step_2, idx_mem].values * 86400,\n",
    "    cmap=\"RdBu\",\n",
    "    norm=mpl_c.SymLogNorm(0.05, 1., vmin=-3, vmax=3),\n",
    "    rasterized=True\n",
    ")\n",
    "\n",
    "bbox = ax_prediction[4].get_position()\n",
    "cax = fig.add_axes([bbox.x0+0.02, bbox.y0-0.02, bbox.x1-bbox.x0-0.04, 0.01])\n",
    "cbar = fig.colorbar(cf_div, cax, orientation=\"horizontal\", extend=\"both\")\n",
    "cbar.set_label(r\"Rate (day$^{-1}$)\", labelpad=8)\n",
    "cbar.set_ticks([-1, 0, 1], labels=[\"-1\", \"0\", \"1\"])\n",
    "cbar.set_ticks([], minor=True)\n",
    "for t in cbar.ax.get_yticklabels():\n",
    "    t.set_horizontalalignment('center')\n",
    "cax.xaxis.get_label().set_verticalalignment(\"baseline\")\n",
    "\n",
    "# Thickness change\n",
    "cf_thick = ax_truth[2].pcolormesh(\n",
    "    ds_aux[\"x_coord\"], ds_aux[\"y_coord\"],\n",
    "    thickness_change_truth[step_1].values,\n",
    "    cmap=\"cmo.balance\",\n",
    "    vmin=-0.25, vmax=0.25,\n",
    "    rasterized=True \n",
    ")\n",
    "cf_thick = ax_truth[5].pcolormesh(\n",
    "    ds_aux[\"x_coord\"], ds_aux[\"y_coord\"],\n",
    "    thickness_change_truth[step_2].values,\n",
    "    cmap=\"cmo.balance\",\n",
    "    vmin=-0.25, vmax=0.25,\n",
    "    rasterized=True \n",
    ")\n",
    "\n",
    "bbox = ax_truth[5].get_position()\n",
    "cax = fig.add_axes([bbox.x0+0.02, bbox.y0-0.02, bbox.x1-bbox.x0-0.04, 0.01])\n",
    "cbar = fig.colorbar(cf_thick, cax, orientation=\"horizontal\", extend=\"both\")\n",
    "cbar.set_label(r\"Change (m/12 h)\", labelpad=8)\n",
    "cbar.set_ticks([], minor=True)\n",
    "for t in cbar.ax.get_yticklabels():\n",
    "    t.set_horizontalalignment('center')\n",
    "cax.xaxis.get_label().set_verticalalignment(\"baseline\")\n",
    "\n",
    "cf_thick = ax_prediction[2].pcolormesh(\n",
    "    ds_aux[\"x_coord\"], ds_aux[\"y_coord\"],\n",
    "    thickness_change_prediction[step_1, idx_mem].values,\n",
    "    cmap=\"cmo.balance\",\n",
    "    vmin=-0.25, vmax=0.25,\n",
    "    rasterized=True \n",
    ")\n",
    "cf_thick = ax_prediction[5].pcolormesh(\n",
    "    ds_aux[\"x_coord\"], ds_aux[\"y_coord\"],\n",
    "    thickness_change_prediction[step_2, idx_mem].values,\n",
    "    cmap=\"cmo.balance\",\n",
    "    vmin=-0.25, vmax=0.25,\n",
    "    rasterized=True \n",
    ")\n",
    "\n",
    "bbox = ax_prediction[5].get_position()\n",
    "cax = fig.add_axes([bbox.x0+0.02, bbox.y0-0.02, bbox.x1-bbox.x0-0.04, 0.01])\n",
    "cbar = fig.colorbar(cf_thick, cax, orientation=\"horizontal\", extend=\"both\")\n",
    "cbar.set_label(r\"Change (m/12 h)\", labelpad=8)\n",
    "cbar.set_ticks([], minor=True)\n",
    "for t in cbar.ax.get_yticklabels():\n",
    "    t.set_horizontalalignment('center')\n",
    "cax.xaxis.get_label().set_verticalalignment(\"baseline\")\n",
    "\n",
    "\n",
    "ax_truth[0].set_ylabel(\"{0:%Y-%m-%d %H:%M}\".format(ds_demo.indexes[\"time\"][step_1]), fontsize=10)\n",
    "ax_truth[3].set_ylabel(\"{0:%Y-%m-%d %H:%M}\".format(ds_demo.indexes[\"time\"][step_2]), fontsize=10)\n",
    "\n",
    "ax_truth[0].set_title(\"Concentration\", fontsize=10)\n",
    "ax_truth[1].set_title(\"Divergence rate\", fontsize=10)\n",
    "ax_truth[2].set_title(\"$\\Delta$ Thickness\", fontsize=10)\n",
    "ax_truth[1].text(0.5, 1.15, s=\"neXtSIM-OPA\", ha=\"center\", va=\"bottom\", transform=ax_truth[1].transAxes, fontsize=14, fontweight=\"bold\")\n",
    "\n",
    "ax_prediction[0].set_title(\"Concentration\", fontsize=10)\n",
    "ax_prediction[1].set_title(\"Divergence rate\", fontsize=10)\n",
    "ax_prediction[2].set_title(\"$\\Delta$ Thickness\", fontsize=10)\n",
    "ax_prediction[1].text(0.5, 1.15, s=\"GenSIM\", ha=\"center\", va=\"bottom\", transform=ax_prediction[1].transAxes, fontsize=14, fontweight=\"bold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65061c19-7702-4544-af18-59a2f60488be",
   "metadata": {},
   "source": [
    "# Congratulations\n",
    "\n",
    "You have reached the end. Now, you know how to use GenSIM and how to reproduce some of the results in the manuscript.\n",
    "\n",
    "Feel free to play around with the settings or to use the model in other experiments.\n",
    "\n",
    "For other questions please contact: Tobias Finn (tobias.finn@enpc.fr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (patched_diffusion)",
   "language": "python",
   "name": "patched_diffusion"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
